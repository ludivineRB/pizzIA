# pizzIA
# ğŸ• Chatbot Polo â€“ Recettes & AllergÃ¨nes de la Pizzeria Marco Fuso

**Chatbot Polo** est un assistant intelligent dÃ©veloppÃ© avec **LangChain**, **Ollama**, **ChromaDB** et **Gradio**, capable de rÃ©pondre Ã  des questions sur les **recettes de pizzas** et les **allergÃ¨nes alimentaires** Ã  partir de documents PDF.

Ce projet met en Å“uvre une architecture **RAG (Retrieval-Augmented Generation)** pour retrouver les informations pertinentes dans des documents vectorisÃ©s, puis gÃ©nÃ©rer une rÃ©ponse contextuelle.

---

## ğŸ” FonctionnalitÃ©s

- Recherche sÃ©mantique dans une base de connaissances vectorisÃ©e (PDFs de recettes et allergÃ¨nes)
- GÃ©nÃ©ration de rÃ©ponses avec un LLM local via Ollama (`mistral`)
- Interface utilisateur conviviale avec **Gradio**
- Persona personnalisÃ© : Polo, le pote de Marco Fuso ğŸ•

---

## ğŸ“ Contenu

### Structure des fichiers :

```
.
â”œâ”€â”€ app_chatbot.py              # Script principal de l'application
â”œâ”€â”€ chroma_db/                  # Base de donnÃ©es vectorielle persistÃ©e
â”œâ”€â”€ documents/                  # Fichiers PDF de recettes et allergÃ¨nes
â”‚   â”œâ”€â”€ marco-fuso-recipe-booklet---final.pdf
â”‚   â”œâ”€â”€ pizza-booklet-french-68623de5495cb223587169.pdf
â”‚   â”œâ”€â”€ Recette-pizza-au-fromage.pdf
â”‚   â””â”€â”€ Tableau-des-allergenes.pdf
â””â”€â”€ README.md                   # Ce fichier
```

---

## âš™ï¸ Technologies utilisÃ©es

- **LangChain** : Orchestration RAG
- **Ollama** : ModÃ¨les locaux (`mistral` pour le LLM, `mxbai-embed-large` pour les embeddings)
- **ChromaDB** : Base vectorielle persistÃ©e
- **Gradio** : Interface utilisateur simple et efficace

---

## ğŸš€ Lancement

### 1. PrÃ©-requis

- Python 3.10 ou supÃ©rieur
- [Ollama installÃ© et lancÃ©](https://ollama.com/)
- ModÃ¨les Ollama suivants tÃ©lÃ©chargÃ©s :
  - `mistral`
  - `mxbai-embed-large`
- Base Chroma existante (gÃ©nÃ©rÃ©e avec un script tel que `module5_creation_db.py`)
- Les documents PDF dans le dossier `documents/`

### 2. Installation

```bash
pip install -r requirements.txt
```

Exemple de `requirements.txt` :

```txt
requests
langchain
langchain-community
langchain-core
langchain-ollama
feedparser
uvicorn
fastapi
python-dotenv
numpy
matplotlib
scikit-learn
chromadb
PyPDF2
langchain-openai 
sqlalchemy 
psycopg2-binary
crewai
crewai_tools
gradio
```

### 3. ExÃ©cution

```bash
python agent.py
```

L'application Gradio se lancera automatiquement dans votre navigateur.

---

## ğŸ’¬ Exemple de questions Ã  poser

- _"Quels sont les ingrÃ©dients de la pizza au fromage ?"_
- _"Cette pizza contient-elle des Å“ufs ou du gluten ?"_
- _"Donne-moi la recette de la pÃ¢te de Marco Fuso."_

---

## âœï¸ Personnalisation

Deux prompts sont dÃ©finis dans le script :

- `template` : classique, centrÃ© sur les recettes
- `template2` : personnage Polo, style amical et conversationnel

Par dÃ©faut, `template2` est utilisÃ© :
```python
prompt = ChatPromptTemplate.from_template(template2)
```

Tu peux basculer vers le style classique en modifiant cette ligne.

---

## ğŸ™‹ Ã€ propos

Projet dÃ©veloppÃ© par **Ludivine Raby**  
Objectif : combiner IA gÃ©nÃ©rative et recherche documentaire vectorielle pour un assistant gastronomique intelligent ğŸ•ğŸ¤–